# 3 確率的勾配降下法
## 3.1 勾配降下法

学習のゴール: 選んだ誤差関数(Error Function) $E\left(w\right)$ に対し、最小値を与える $w = arg\min _{ w }{ E\left( w \right)  } $を求めること

 - しかし、$E\left(w\right)$ は一般的な凸関数ではないので、絶対的(大域的)な極小点 $w$ を求めることは通常不可能
 - そのため, $E\left(w\right)$ の局所的な極小点 $w$ を求めることを考える

極小解は、何らかの初期値を出発点に $w$ を繰り返し更新する反復計算によって求める。そうする方法はいくつかあるが、中でも最も簡単な方法が**<font color="blue">勾配降下法</font>**(gradient descent method)。

勾配(gradient)が与えられたとき
$$
\nabla E\equiv \frac { \partial E }{ \partial w } =\left( \frac { \partial E }{ \partial { w }_{ 1 } } ,\cdots ,\frac { \partial E }{ \partial { w }_{ M } }  \right) ^{ T } \qquad (3.1)
$$

$$
w^{(t+1)} = w^{(t)} - \epsilon \nabla E \qquad (3.2)
$$

 - $M$ : $w$の成分数
 - $\epsilon$ : **学習係数**(learning rate)

のように$w$を負の勾配方向($- \nabla E$)に少し動かし、これを繰り返し更新する。

> **学習係数の決定方法**
>
> $\mathrm {w}^{(t)}$は、
>
> - $\epsilon$が十分小さければ、$t$の増加に伴って$E\left( \mathrm {w}^{(t)} \right)$を確実に減少させる。したがって、$t$を大きくすれば(何度も更新を繰り返せば)、いつかは極小点に到達できる
>     - ただし、$E\left(\mathrm {w}\right)$の形状と$\epsilon$の大きさによっては、$E\left(\mathrm {w}\right)$が増大してしまうこともある
> - $\epsilon$が小さすぎると、$\mathrm {w}$の1回の更新量が小さくなってしまうので、反復回数が増加し学習にかかる時間が大きくなる
>
> というように学習係数$\epsilon$の決定に依存する。そのため、学習係数の決定は大変重要な問題で、学習がうまく行えるかどうかの鍵の1つを握っている

非線形関数の最小化手法には、勾配降下法のほかにニュートン法やその派生方法もある。勾配降下法は、「望む極小解への収束が遅い」「学習係数の決定に学習が大きく左右される」ことから、ニュートン法などの手法が適用できる場合に、わざわざ勾配降下法を使うことはない。ただし、目的関数の2次微分の計算が難しい場合には勾配降下法は数少ないお有効な方法である。ディープネットの学習はまさにその場合にあたる。

---
## 3.2 確率的勾配降下法
回帰やクラス分類のいずれであっても、損失関数は各訓練データに対しての損失関数の和として定義される。

$$
E\left( \mathrm {w} \right) = \sum _{i=1}^{N}{E_{i}\left( \mathrm {w} \right)}
$$

$w$の更新式(3.2)では、この$E\left( \mathrm{w} \right)$の勾配を用いる。このように全ての訓練データを用いてパラメータ$\mathrm {w}$の更新を行う学習を**バッチ学習**(**batch learning**)と呼ぶ。

これに対して、**一部の訓練データ**(究極には1つだけの訓練データ)だけを使ってパラメータ更新を行う方法を**確率的勾配降下法**(SGD : **stochastic gradient descent**)と呼ぶ。この方法では、$\mathrm {w}$の更新は1つの訓練データ$i$について計算される損失関数$E_{i}\left( \mathrm {w} \right)$の勾配$\nabla E_{i}$を計算し、

$$
\mathrm {w}^{(t + 1)} = \mathrm {w}^{(t)} - \epsilon \nabla E_{i}
$$

のように$\mathrm {w}$を更新する。次の$\mathrm {w}^{(t + 1)}$の更新の際は、別の訓練データ$i^{\prime}$を取り出し、これを使って同様に勾配$\nabla E_{i^{\prime}}\left(\mathrm {w}\right)$を評価し、更新する。

$$
\mathrm {w}^{(t + 2)} = \mathrm {w}^{(t + 1)} - \epsilon \nabla E_{i^{\prime}}
$$

このように訓練データを毎回取り替え、$\mathrm {w}$を更新していく。

> **確率的勾配降下法の利点** : バッチ学習の勾配降下法に対し、確率的勾配降下法にはいくつかの長所があることから、ディープネットの学習ではより一般的である。
>
> - 訓練データに冗長性(じょうちょうせい)がある場合、計算効率が向上し学習が速く実行できる
>     - 極端な例) 手元の訓練データをそっくり複製し、データ数を2倍に「水増し」したとする。この水増しされたデータで学習しても学習の良し悪しに影響はないものの勾配降下法では計算コストが2倍になる。一方、確率的勾配降下法では学習内容・計算量ともに変化なし。
> - 反復計算が望まない(損失関数の値が相対的にそれほど小さくない)局所的な極小解にトラップされてしまうリクスを低減できる
> - パラメータの更新が小刻みに行われるので学習の途中経過をより細かく監視できることから、オンラインでの学習すなわち、訓練データの収集と最適化の計算を同時並行で行える

---
## 3.3 「ミニバッチ」の利用

規模が大きいニューラルネットの学習は大きな計算コストを要するため、数値計算を効率化するには、計算機が持つ並列計算資源の利用が不可欠である。そのため、重みの更新を訓練データ1つ単位で行うのではなく、少数の訓練データの集合をひとまとめにし、その単位で重みを更新する。

 - ひとまとめにしたサンプル集合は**ミニバッチ**(**minibatch**)と呼ぶ。

<img src="./imgs/03確率的勾配降下法/ミニバッチ.jpg" width="70%">

具体的には次のように計算する。

 - $D_{t}$ : 1つのミニバッチ。少数の訓練データの集合を指し、添字は$t$回目の更新ごとにその訓練データ集合が変わることを表す
 - $N_{t} = \left| D_{t} \right|$ : ミニバッチ$t$が含む訓練データ数

$D_{t}$の含む全訓練データに対する誤差

$$
E_{t}\left( w \right) = \frac {1}{N_{t}} \sum _{i \in D_{t}}{E_{i}\left( w \right)}
$$

を計算し、その勾配の方向にパラメータを更新する。なお、**<font color="red">このように$E_{t}\left( w \right)$を$N_{t}$で正規化すると、ミニバッチのサイズ(訓練データ数)を変えたとき、それに合わせて学習係数を調整しなければなら煩わしさを避けることができる</font>**。

> - ミニバッチの作成 : ミニバッチ$D_{t}(t=1,2,\dots)$は学習開始前に作成し、固定する。
> - ミニバッチ$D_{t}$のサイズ : ミニバッチのサイズを決める系統的なやり方はないが、確率的勾配降下法のメリットと並列計算資源の有効利用を天秤にかけ、大体**10~100**サンプル前後とすることが多い
>     - 多クラス分類問題の場合 : ミニバッチ間の重みの更新のばらつきを平準化するために、ミニバッチそれぞれに各クラスから1つ以上のサンプルを入れるのが理想
> 	       - クラス数が10~100程度 & 各クラスの出現頻度が等しい場合 : 分類すべきクラス数と同サイズのミニバッチを作るのが良い
> 	       - クラス数が100以上ある場合 : 訓練データをランダムにシャッフルした後、ミニバッチに分割する

ミニバッチのサイズをあまり大きくすることは、確率的勾配降下法のよさを損なうことになり、あまり良くない。サイズを大きくすると、ミニバッチ間で計算される勾配のばらつきが小さくなり、$\mathrm {w}$の更新量が安定するので、学習係数$\epsilon$を大きくでき、それだけ学習が速く進む効果がある。しかし一般に、ミニバッチのサイズを$N$倍しても、$\epsilon$を$N$倍にまで大きくすることはできないので、トータルの計算速度は逆に低下する。

---
## 3.4 汎化性能と過適合
ここまでは、訓練データに対する誤差(誤差関数の値)を最小化することを考えてきた。学習の本当の目的は、与えらた訓練データではなくて、これから与えられるはずの未知のデータ$\mathrm {x}$に対して正しい推定を行えるようにすることである。

 - **訓練誤差**(**training error**) : 訓練データに対する誤差
 - **汎化誤差**(**generalization error**) : サンプルの母集団に対する誤差の期待値

より正確にいうと、学習は汎化誤差を小さくすることが目標だが、汎化誤差は統計的な期待値であり、訓練誤差のように実際に計算することができない。そこで、訓練データとは別のデータ集合、テストデータを準備し、これに対して訓練誤差と同じ方法で計算される誤差を汎化誤差の目安とする。この誤差を**テスト誤差**(**test error**)という。

 - **テスト誤差**(**test error**) : テストデータに対する誤差

学習によるパラメータの更新に伴って、訓練誤差およびテスト誤差がどのように変化するかのイメージ図を示す。これらの曲線のことを**学習曲線**(**learning curve**)と呼ぶ。

<img src="./imgs/03確率的勾配降下法/学習曲線のイメージ.png" width="80%">

上図のように学習が進むほど訓練誤差は単調減少するが、テスト誤差はそうなるとは限らない。このように訓練誤差と汎化誤差が乖離した状態のことを、**過適合**(**overfitting**)または**過剰適合**、**過学習**(**overlearning**)と呼ぶ。

テスト誤差が汎化誤差をよく近似できているとすると、テスト誤差が最小となる状態が理想である。上述のようにパラメータの更新に伴ってテスト誤差が増加するようならそれ以降の学習はむしろ有害なので、その時点で学習を終了する。これは**早期終了**(**early stopping**)あるいは**早期打ち切り**と呼ばれ、昔からニューラルネット の学習テクニックの1つである。

いかにこのような過学習を起こすことなく、**<font color="blue">よりテスト誤差($ \risingdotseq $汎化誤差)を小さくできるかがニューラルネットの学習の鍵である</font>**。そのためには以下のようなことを行い、その実現を目指す。

 - ネットワークの層数やユニット数などの構造、あるいは学習係数などのハイパーパラメータをうまく調整する
 - 正則化の方法や学習のためのトリックを利用する

---
## 3.5 過適合の緩和
### 3.5.1 正則化

過学習は、**学習時に誤差関数の浅い局所解にトラップされた状況である**と解釈できる。

 - ネットワークの自由度(主に重みの数)が高いほど、そうなる可能性が大きくなるといえる
 - ただし、ネットワークの自由度はその表現能力に直結するため、過学習の解決策として単純にネットワークの自由度を減らすことは、問題の複雑さと比べ過大な自由度を持つ場合を除き、あまり望ましくない

→学習時に重みの自由度を制約する**<font color="blue">正則化</font>**(**regularization**)によって、以上の問題を緩和しようとする方法が提案されている。

### 3.5.2 重みの制約
正則化には、以下のような制約する方法がある。

#### 重み減衰(weight decay)
誤差関数に重みの二乗和(二乗ノルム)を加算し、これを最小化する。最終項の追加により、学習時により小さい重みが選好されるようになる。

$$
E_{t}\left( \mathrm {w} \right) = \frac { 1 }{ N_{t} } \sum _{i \in D_{t}}{ E_{i}\left( \mathrm {w} \right) } + \frac {\lambda}{2} {\left\| \mathrm {w} \right\| }^{2}
$$

 - $\lambda$ : **正則化の強さを制御するパラメータ**。一般に$\lambda = 0.01 \sim 0.00001$程度の範囲から選ぶ。

勾配降下法の更新式は

$$
\mathrm {w}^{(t + 1)} = \mathrm {w}^{(t)} - \epsilon \left( \frac {1}{N_{t}} \sum _{i \in D_{t}}{\nabla E_{i}} + \lambda \mathrm {w}^{(t)} \right)
$$

となり、重みは自身の大きさに比例した速さで常に減衰するように修正される。

 - 重み減衰は、ネットワークの重み$\mathrm {W}^{(l)}$だけに適用し、バイアス$\mathrm {b}^{(l)}$には適用しない。バイアスは総数が小さいので過学習が起こしにくく、ときに大きな値をとる必要があるからである。

#### 重み上限
重みの大きさの上限を制約する方法であり、各ユニットの入力側結合の、重みの二乗和の上限を制約する方法である。すなわち、$l$層のユニット$j$について考えると、これが$l - 1$層のユニット$i = 1, \dots, I$からの出力を受け取るとすると、その間の結合重み$w_{ji}$が

$$
\sum _{i}{w_{ji}^{2}} < c
$$

を満たすように重みを制約する。それには、この不等式が満たされていない場合は$w_{j1}, \dots, w_{jI}$に1以下の定数を掛け、満たされるようにする。

これは比較的最近提案された方法で、重み減衰を上回る効果があり、後述するドロップアウトとともに用いると特に高い効果があることが報告されている。


### 3.5.3 ドロップアウト
**<font color="blue">ドロップアウト</font>** : 多層ネットワークのユニットを確率的に選別して学習する方法

 - 多くの場面で大変よい結果が得られるため、現在広く使われている。

ドロップアウトは、ネットワークの学習過程と学習後の推論過程を、それぞれ以下のように修正する。

> #### 学習時
> 中間層の各層と入力層のユニットを決まった割合$p$でランダムに選出し、それら以外を無効化、つまりそもそも存在しないかのように扱う(つまりこれらの層のユニットは確率$p$で存在する)。
>
<img src="./imgs/03確率的勾配降下法/ドロップアウトの学習時の操作.png" style="width: 75%">
>
> そして、選出したユニットのみからなる「仮の姿」のネットワークを最適化する。すなわち、訓練データをネットワークに入力する順伝播計算を行い、誤差を求めた後、逆伝搬計算を行って誤差の勾配を計算し、重みを更新する。
> $$
E \rightarrow \nabla E \rightarrow \mathrm {W}^{(t+1)}
$$
> 

 - ユニットの選出は重み$\mathrm {w}$の更新のたびにランダムに行う
 - ミニバッチを使っている場合は、ミニバッチ単位でユニットを選び直すことになる
 - ユニットの選出確率$p$の値は各層で変わっても構わない

<br>

> #### 学習終了後の推論時
> すべてのユニットを使って順伝播計算を行う。ただし、ドロップアウトで無効化の対象とした層のユニットはすべて一律にその出力を$p$倍する。

![](./imgs/03確率的勾配降下法/ドロップアウトの推論時の操作.png)

> これは、これらの層では推論時のユニット数が学習時と比べて$1/p$倍に増えていることを補償している。


#### ドロップアウトの狙い

 - 学習時にネットワークの自由度を強制的に小さくし、過適合を避けること
 - また、こうすることはドロップアウト時の(ユニットをランダムに無効化した)ネットワークを多数独立に学習し、推論時にそれらの結果を平均するのと同じ効果(3.6.3項)があると考えられている
 	- 複数のネットワークの平均をとると推論の精度が一般に向上することが知られており、ドロップアウトはこれと同じ効果をより小さな計算コストで得ていると解釈できる

ドロップアウトのほかにもネットワークの一部を学習時にランダムに無効化する類似手法として、

 - ドロップコネクト
 - 確率的最大プーリング

がある。

---
## 3.6 学習のトリック

以下に紹介する方法は、モデルの汎化性能を向上させたり、高速な学習を可能にするものである。その多くは厳密な理論を伴わないノウハウのようなものがあるが、実際に効果が認められていることが多く、古くから利用されている。

### 3.6.1 データの正規化

 - 使用シーン : 学習データが偏りを含む場合
 - 注意 : テストデータおよび推論時の各データにも同じ前処理(変換)を施す必要がある

各成分の平均値が0、分散が1となる標準化変量に変換する。

$$
s_{ji} = \frac {x_{ji} - \bar {x}_{i}}{\sigma_{i}}\\
\bar {x}_{i} = \frac {1}{N} \sum _{j=1}^{N}{x_{ji}}\\
\sigma _{ i }=\sqrt { \frac { 1 }{ N } \sum _{ j=1 }^{ N }{ { \left( { x }_{ ji }-{ \bar { x }  }_{ i } \right)  }^{ 2 } }  } 
$$

ただし、成分の値が0か1のダミー変数の場合は、そのままにしたほうがよい場合もある。

### 3.6.2 データ拡張

 - **データ拡張**(data augmentation)とは : 手持ちのサンプルデータに何らかの加工を施し、量を「水増し」すること
 - 使用シーン : 学習データの量が足りないとき。(学習データの量が不足していることは過学習を起こす最大の原因)
 - 注意 : データのばらつき方が予想できる場合、とくに有効

### 3.6.3 複数ネットの平均

複数の異なるニューラルネットを組み合わせると、一般に推定精度を向上できる。

### 3.6.4 学習係数$\epsilon$の決め方

### 3.6.5 モメンタム

### 3.6.6 重みの初期化

### 3.6.7 サンプルの順序
